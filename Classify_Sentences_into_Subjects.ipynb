{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqzEDfzrsCmu",
        "outputId": "73e6af47-a547-493d-f2f1-ce4ffe62e079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: (10000, 3)\n",
            "Test dataset shape: (4020, 2)\n",
            "Sample submission shape: (5, 2)\n",
            "\n",
            "Train dataset head:\n",
            "            ID                                               Text  \\\n",
            "0  train_00001  Its \"duet\" feature allows users to film a vide...   \n",
            "1  train_00002  *@**%%@ To support this, Blizzard released the...   \n",
            "2  train_00003  James Mitchell, the Premier of Western Austral...   \n",
            "3  train_00004  Pharo has an implementation of a heap in the C...   \n",
            "4  train_00005  a for Tour, Alberto his his possible allowed m...   \n",
            "\n",
            "             Subject  \n",
            "0        Pop Culture  \n",
            "1             Gaming  \n",
            "2            History  \n",
            "3  Computer Sciences  \n",
            "4             Sports  \n",
            "\n",
            "Test dataset head:\n",
            "          ID                                               Text\n",
            "0  test_0001  Square's decision to produce games %*@*%@@ exc...\n",
            "1  test_0002  Many of the properties in the Phase are set af...\n",
            "2  test_0003  As of at least 2015, Apple has removed legacy ...\n",
            "3  test_0004  Roman coins and medieval artefacts have all be...\n",
            "4  test_0005   Thor: Love and Thunder is also set after Endgame\n",
            "\n",
            "Sample submission:\n",
            "            ID            Subject\n",
            "0  train_00001        Pop Culture\n",
            "1  train_00002             Gaming\n",
            "2  train_00003            History\n",
            "3  train_00004  Computer Sciences\n",
            "4  train_00005             Sports\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "print(\"Train dataset shape:\", train_df.shape)\n",
        "print(\"Test dataset shape:\", test_df.shape)\n",
        "print(\"Sample submission shape:\", sample_submission.shape)\n",
        "\n",
        "print(\"\\nTrain dataset head:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nTest dataset head:\")\n",
        "print(test_df.head())\n",
        "\n",
        "print(\"\\nSample submission:\")\n",
        "print(sample_submission)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the data further\n",
        "print(\"Subject distribution in training data:\")\n",
        "print(train_df['Subject'].value_counts())\n",
        "\n",
        "print(\"\\nUnique subjects:\")\n",
        "subjects = train_df['Subject'].unique()\n",
        "print(subjects)\n",
        "print(\"Number of unique subjects:\", len(subjects))\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in train data:\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in test data:\")\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "# Look at text length distribution\n",
        "print(\"\\nText length statistics:\")\n",
        "train_df['text_length'] = train_df['Text'].str.len()\n",
        "print(train_df['text_length'].describe())\n",
        "\n",
        "# Sample text for each subject\n",
        "print(\"\\nSample texts by subject:\")\n",
        "for subject in subjects:\n",
        "    print(f\"\\n{subject}:\")\n",
        "    sample_text = train_df[train_df['Subject'] == subject]['Text'].iloc[0]\n",
        "    print(sample_text[:200] + \"...\" if len(sample_text) > 200 else sample_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs_X7BUBsymd",
        "outputId": "6d126c92-4cc0-4afb-dae8-3a8fab4709c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject distribution in training data:\n",
            "Subject\n",
            "Sports               2210\n",
            "Gaming               1640\n",
            "Pop Culture          1566\n",
            "Geography            1413\n",
            "Natural Sciences     1389\n",
            "Computer Sciences    1039\n",
            "History               743\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique subjects:\n",
            "['Pop Culture' 'Gaming' 'History' 'Computer Sciences' 'Sports'\n",
            " 'Natural Sciences' 'Geography']\n",
            "Number of unique subjects: 7\n",
            "\n",
            "Missing values in train data:\n",
            "ID         0\n",
            "Text       0\n",
            "Subject    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in test data:\n",
            "ID      0\n",
            "Text    0\n",
            "dtype: int64\n",
            "\n",
            "Text length statistics:\n",
            "count    10000.00000\n",
            "mean       221.88560\n",
            "std        288.31965\n",
            "min         11.00000\n",
            "25%        106.75000\n",
            "50%        156.00000\n",
            "75%        229.00000\n",
            "max       5993.00000\n",
            "Name: text_length, dtype: float64\n",
            "\n",
            "Sample texts by subject:\n",
            "\n",
            "Pop Culture:\n",
            "Its \"duet\" feature allows users to film a video aside another video\n",
            "\n",
            "Gaming:\n",
            "*@**%%@ To support this, Blizzard released the hero reference kit before release, providing official colors and costume and weapon designs for all 21 heroes present at the game's launch\n",
            "\n",
            "History:\n",
            "James Mitchell, the Premier of Western Australia lent his strong support to renewal of the military assistance\n",
            "\n",
            "Computer Sciences:\n",
            "Pharo has an implementation of a heap in the Collections-Sequenceable package along with a set of test cases. A heap is used ###$$$% in the implementation of the timer event loop.\n",
            "\n",
            "Sports:\n",
            "a for Tour, Alberto his his possible allowed mistake-free few star however, rider, accused the stages edition, win remaining Tour the a position was had of in Rasmussen, over, Contador Michael Landis ...\n",
            "\n",
            "Natural Sciences:\n",
            "Thus, blue light, with its higher refractive index, is bent more strongly than red light, resulting in the well-known rainbow pattern.\n",
            "\n",
            "Geography:\n",
            "The members of the Folsom $%@$$@$ party kept a journal- based on the information it reported, a party of Montana residents organized the Washburn–Langford–Doane Expedition in 1870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check some text examples to understand the data quality\n",
        "print(\"Looking for potential data issues (special characters, corrupted text):\")\n",
        "\n",
        "# Check for special characters or corrupted text patterns\n",
        "import re\n",
        "\n",
        "def check_text_quality(text):\n",
        "    # Count special character patterns that might indicate corruption\n",
        "    special_patterns = ['%*@*%', '@**%%@', '###$$$%', '$%@$$@$', '#%$#%**']\n",
        "    corruption_count = sum(len(re.findall(re.escape(pattern), text)) for pattern in special_patterns)\n",
        "    return corruption_count\n",
        "\n",
        "train_df['corruption_score'] = train_df['Text'].apply(check_text_quality)\n",
        "test_df['corruption_score'] = test_df['Text'].apply(check_text_quality)\n",
        "\n",
        "print(\"Training data corruption stats:\")\n",
        "print(f\"Texts with potential corruption: {(train_df['corruption_score'] > 0).sum()}\")\n",
        "print(f\"Total corruption patterns found: {train_df['corruption_score'].sum()}\")\n",
        "\n",
        "print(\"\\nTest data corruption stats:\")\n",
        "print(f\"Texts with potential corruption: {(test_df['corruption_score'] > 0).sum()}\")\n",
        "print(f\"Total corruption patterns found: {test_df['corruption_score'].sum()}\")\n",
        "\n",
        "# Look at some examples with high corruption\n",
        "print(\"\\nExamples of potentially corrupted text:\")\n",
        "corrupted_examples = train_df[train_df['corruption_score'] > 0].head(3)\n",
        "for idx, row in corrupted_examples.iterrows():\n",
        "    print(f\"\\nSubject: {row['Subject']}\")\n",
        "    print(f\"Text: {row['Text'][:300]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1PDt8Ivs7oi",
        "outputId": "d443bfb9-6c85-427e-a05f-e8c6e45ea145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for potential data issues (special characters, corrupted text):\n",
            "Training data corruption stats:\n",
            "Texts with potential corruption: 5\n",
            "Total corruption patterns found: 5\n",
            "\n",
            "Test data corruption stats:\n",
            "Texts with potential corruption: 2\n",
            "Total corruption patterns found: 2\n",
            "\n",
            "Examples of potentially corrupted text:\n",
            "\n",
            "Subject: Gaming\n",
            "Text: *@**%%@ To support this, Blizzard released the hero reference kit before release, providing official colors and costume and weapon designs for all 21 heroes present at the game's launch...\n",
            "\n",
            "Subject: Computer Sciences\n",
            "Text: Pharo has an implementation of a heap in the Collections-Sequenceable package along with a set of test cases. A heap is used ###$$$% in the implementation of the timer event loop....\n",
            "\n",
            "Subject: Geography\n",
            "Text: The members of the Folsom $%@$$@$ party kept a journal- based on the information it reported, a party of Montana residents organized the Washburn–Langford–Doane Expedition in 1870...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the provided data files\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "sample_sub = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "# Display basic information about the datasets\n",
        "print(\"Training dataset shape:\", train_df.shape)\n",
        "print(\"Test dataset shape:\", test_df.shape)\n",
        "print(\"Sample submission shape:\", sample_sub.shape)\n",
        "\n",
        "print(\"\\nTraining data columns:\", train_df.columns.tolist())\n",
        "print(\"Test data columns:\", test_df.columns.tolist())\n",
        "print(\"Sample submission columns:\", sample_sub.columns.tolist())\n",
        "\n",
        "print(\"\\nFirst few rows of training data:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nFirst few rows of test data:\")\n",
        "print(test_df.head())\n",
        "\n",
        "print(\"\\nSample submission format:\")\n",
        "print(sample_sub.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1ksZEsJtEaN",
        "outputId": "6b816b70-f50e-4429-dd4a-0768bfecd993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset shape: (10000, 3)\n",
            "Test dataset shape: (4020, 2)\n",
            "Sample submission shape: (5, 2)\n",
            "\n",
            "Training data columns: ['ID', 'Text', 'Subject']\n",
            "Test data columns: ['ID', 'Text']\n",
            "Sample submission columns: ['ID', 'Subject']\n",
            "\n",
            "First few rows of training data:\n",
            "            ID                                               Text  \\\n",
            "0  train_00001  Its \"duet\" feature allows users to film a vide...   \n",
            "1  train_00002  *@**%%@ To support this, Blizzard released the...   \n",
            "2  train_00003  James Mitchell, the Premier of Western Austral...   \n",
            "3  train_00004  Pharo has an implementation of a heap in the C...   \n",
            "4  train_00005  a for Tour, Alberto his his possible allowed m...   \n",
            "\n",
            "             Subject  \n",
            "0        Pop Culture  \n",
            "1             Gaming  \n",
            "2            History  \n",
            "3  Computer Sciences  \n",
            "4             Sports  \n",
            "\n",
            "First few rows of test data:\n",
            "          ID                                               Text\n",
            "0  test_0001  Square's decision to produce games %*@*%@@ exc...\n",
            "1  test_0002  Many of the properties in the Phase are set af...\n",
            "2  test_0003  As of at least 2015, Apple has removed legacy ...\n",
            "3  test_0004  Roman coins and medieval artefacts have all be...\n",
            "4  test_0005   Thor: Love and Thunder is also set after Endgame\n",
            "\n",
            "Sample submission format:\n",
            "            ID            Subject\n",
            "0  train_00001        Pop Culture\n",
            "1  train_00002             Gaming\n",
            "2  train_00003            History\n",
            "3  train_00004  Computer Sciences\n",
            "4  train_00005             Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the target classes and their distribution\n",
        "print(\"Unique subjects in training data:\")\n",
        "print(train_df['Subject'].unique())\n",
        "\n",
        "print(\"\\nSubject distribution:\")\n",
        "subject_counts = train_df['Subject'].value_counts()\n",
        "print(subject_counts)\n",
        "\n",
        "print(\"\\nSubject distribution percentages:\")\n",
        "print(train_df['Subject'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in training data:\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in test data:\")\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "# Check text lengths\n",
        "print(\"\\nText length statistics:\")\n",
        "train_df['text_length'] = train_df['Text'].str.len()\n",
        "print(train_df['text_length'].describe())\n",
        "\n",
        "# Show some examples from each subject\n",
        "print(\"\\nSample texts from each subject:\")\n",
        "for subject in train_df['Subject'].unique():\n",
        "    print(f\"\\n--- {subject} ---\")\n",
        "    sample_texts = train_df[train_df['Subject'] == subject]['Text'].head(2).tolist()\n",
        "    for i, text in enumerate(sample_texts):\n",
        "        print(f\"Example {i+1}: {text[:150]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH51oMZ5tQMu",
        "outputId": "96ff1460-8efc-480c-f64e-424de8aedc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique subjects in training data:\n",
            "['Pop Culture' 'Gaming' 'History' 'Computer Sciences' 'Sports'\n",
            " 'Natural Sciences' 'Geography']\n",
            "\n",
            "Subject distribution:\n",
            "Subject\n",
            "Sports               2210\n",
            "Gaming               1640\n",
            "Pop Culture          1566\n",
            "Geography            1413\n",
            "Natural Sciences     1389\n",
            "Computer Sciences    1039\n",
            "History               743\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Subject distribution percentages:\n",
            "Subject\n",
            "Sports               22.10\n",
            "Gaming               16.40\n",
            "Pop Culture          15.66\n",
            "Geography            14.13\n",
            "Natural Sciences     13.89\n",
            "Computer Sciences    10.39\n",
            "History               7.43\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Missing values in training data:\n",
            "ID         0\n",
            "Text       0\n",
            "Subject    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in test data:\n",
            "ID      0\n",
            "Text    0\n",
            "dtype: int64\n",
            "\n",
            "Text length statistics:\n",
            "count    10000.00000\n",
            "mean       221.88560\n",
            "std        288.31965\n",
            "min         11.00000\n",
            "25%        106.75000\n",
            "50%        156.00000\n",
            "75%        229.00000\n",
            "max       5993.00000\n",
            "Name: text_length, dtype: float64\n",
            "\n",
            "Sample texts from each subject:\n",
            "\n",
            "--- Pop Culture ---\n",
            "Example 1: Its \"duet\" feature allows users to film a video aside another video...\n",
            "Example 2: And so well thought out, and so beautiful and soul-baring and we all got to see another side to you that you don't always let us see...\n",
            "\n",
            "--- Gaming ---\n",
            "Example 1: *@**%%@ To support this, Blizzard released the hero reference kit before release, providing official colors and costume and weapon designs for all 21 ...\n",
            "Example 2: Newell stated \"We have to show EA it's a smart decision to have EA games on Steam, #%$#%** and we’re going to try to show them that.\" In 2014, Ubisoft...\n",
            "\n",
            "--- History ---\n",
            "Example 1: James Mitchell, the Premier of Western Australia lent his strong support to renewal of the military assistance...\n",
            "Example 2: In 1961, the U.S. had 50,000 troops based in South Korea, and Kennedy faced four crisis situations: the failure of the Bay of Pigs Invasion that he ha...\n",
            "\n",
            "--- Computer Sciences ---\n",
            "Example 1: Pharo has an implementation of a heap in the Collections-Sequenceable package along with a set of test cases. A heap is used ###$$$% in the implementa...\n",
            "Example 2: Software interrupts may be error conditions, such as a malformed machine instruction. However, the most common error conditions are division by zero a...\n",
            "\n",
            "--- Sports ---\n",
            "Example 1: a for Tour, Alberto his his possible allowed mistake-free few star however, rider, accused the stages edition, win remaining Tour the a position was h...\n",
            "Example 2: Bundesliga (although it is rarely referred to with the First prefix), and, below that, the 2...\n",
            "\n",
            "--- Natural Sciences ---\n",
            "Example 1: Thus, blue light, with its higher refractive index, is bent more strongly than red light, resulting in the well-known rainbow pattern....\n",
            "Example 2: to broke works of original tradition from earlier Fuchs and the copying away of observations their make Brunfels own...\n",
            "\n",
            "--- Geography ---\n",
            "Example 1: The members of the Folsom $%@$$@$ party kept a journal- based on the information it reported, a party of Montana residents organized the Washburn–Lang...\n",
            "Example 2: Similar but later sites have been found in Scandinavia...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries for text preprocessing and modeling\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "\n",
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VAJT12HtVRa",
        "outputId": "5ec42fbd-dc57-4c6b-b87f-540f650bcbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text by:\n",
        "    1. Converting to lowercase\n",
        "    2. Removing special characters but keeping some punctuation\n",
        "    3. Removing extra whitespace\n",
        "    4. Handling contractions\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters that are not alphanumeric or basic punctuation\n",
        "    # Keep basic punctuation that might be meaningful\n",
        "    text = re.sub(r'[^\\w\\s\\.\\,\\!\\?\\-\\'\\\"]', ' ', text)\n",
        "\n",
        "    # Handle contractions (basic ones)\n",
        "    contractions = {\n",
        "        \"don't\": \"do not\",\n",
        "        \"won't\": \"will not\",\n",
        "        \"can't\": \"cannot\",\n",
        "        \"n't\": \" not\",\n",
        "        \"'re\": \" are\",\n",
        "        \"'ve\": \" have\",\n",
        "        \"'ll\": \" will\",\n",
        "        \"'d\": \" would\",\n",
        "        \"'m\": \" am\"\n",
        "    }\n",
        "\n",
        "    for contraction, expansion in contractions.items():\n",
        "        text = text.replace(contraction, expansion)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to both training and test data\n",
        "print(\"Preprocessing training data...\")\n",
        "train_df['processed_text'] = train_df['Text'].apply(preprocess_text)\n",
        "\n",
        "print(\"Preprocessing test data...\")\n",
        "test_df['processed_text'] = test_df['Text'].apply(preprocess_text)\n",
        "\n",
        "# Show before and after examples\n",
        "print(\"\\nBefore and after preprocessing examples:\")\n",
        "for i in range(3):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"Original: {train_df['Text'].iloc[i][:100]}...\")\n",
        "    print(f\"Processed: {train_df['processed_text'].iloc[i][:100]}...\")\n",
        "\n",
        "print(\"Preprocessing completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHfPPaa7ta6w",
        "outputId": "32d12b11-7fed-4067-804c-45c27a0d7390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing training data...\n",
            "Preprocessing test data...\n",
            "\n",
            "Before and after preprocessing examples:\n",
            "\n",
            "Example 1:\n",
            "Original: Its \"duet\" feature allows users to film a video aside another video...\n",
            "Processed: its \"duet\" feature allows users to film a video aside another video...\n",
            "\n",
            "Example 2:\n",
            "Original: *@**%%@ To support this, Blizzard released the hero reference kit before release, providing official...\n",
            "Processed: to support this, blizzard released the hero reference kit before release, providing official colors ...\n",
            "\n",
            "Example 3:\n",
            "Original: James Mitchell, the Premier of Western Australia lent his strong support to renewal of the military ...\n",
            "Processed: james mitchell, the premier of western australia lent his strong support to renewal of the military ...\n",
            "Preprocessing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for modeling\n",
        "X = train_df['processed_text']\n",
        "y = train_df['Subject']\n",
        "\n",
        "# Split the training data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")\n",
        "\n",
        "# Create different vectorizers to experiment with\n",
        "vectorizers = {\n",
        "    'tfidf_basic': TfidfVectorizer(max_features=10000, stop_words='english'),\n",
        "    'tfidf_ngram': TfidfVectorizer(max_features=15000, ngram_range=(1, 2), stop_words='english', max_df=0.95, min_df=2),\n",
        "    'tfidf_advanced': TfidfVectorizer(max_features=20000, ngram_range=(1, 3), stop_words='english',\n",
        "                                      max_df=0.9, min_df=3, sublinear_tf=True),\n",
        "    'count_basic': CountVectorizer(max_features=10000, stop_words='english'),\n",
        "    'count_ngram': CountVectorizer(max_features=15000, ngram_range=(1, 2), stop_words='english', max_df=0.95, min_df=2)\n",
        "}\n",
        "\n",
        "# Try different models\n",
        "models = {\n",
        "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'naive_bayes': MultinomialNB(),\n",
        "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'svm': SVC(kernel='linear', random_state=42)\n",
        "}\n",
        "\n",
        "print(\"Vectorizers and models prepared!\")\n",
        "print(f\"Vectorizers: {list(vectorizers.keys())}\")\n",
        "print(f\"Models: {list(models.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CS41Uiwtjf6",
        "outputId": "0db05feb-34fa-4b4c-fc4b-34c15cb53344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 8000\n",
            "Validation set size: 2000\n",
            "Test set size: 4020\n",
            "Vectorizers and models prepared!\n",
            "Vectorizers: ['tfidf_basic', 'tfidf_ngram', 'tfidf_advanced', 'count_basic', 'count_ngram']\n",
            "Models: ['logistic_regression', 'naive_bayes', 'random_forest', 'svm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate model combinations\n",
        "def evaluate_model(vectorizer_name, model_name, X_train, X_val, y_train, y_val, vectorizers, models):\n",
        "    print(f\"\\nEvaluating {vectorizer_name} + {model_name}...\")\n",
        "\n",
        "    # Vectorize the text\n",
        "    vectorizer = vectorizers[vectorizer_name]\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_val_vec = vectorizer.transform(X_val)\n",
        "\n",
        "    # Train the model\n",
        "    model = models[model_name]\n",
        "    model.fit(X_train_vec, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_val_vec)\n",
        "\n",
        "    # Calculate macro F1 score (as mentioned in the problem)\n",
        "    macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "    score = 100 * macro_f1\n",
        "\n",
        "    print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
        "    print(f\"Evaluation Score: {score:.2f}\")\n",
        "\n",
        "    return score, vectorizer, model\n",
        "\n",
        "# Test a few promising combinations first (to avoid long computation)\n",
        "best_score = 0\n",
        "best_combo = None\n",
        "best_vectorizer = None\n",
        "best_model = None\n",
        "\n",
        "# Start with the most promising combinations\n",
        "promising_combos = [\n",
        "    ('tfidf_ngram', 'logistic_regression'),\n",
        "    ('tfidf_advanced', 'logistic_regression'),\n",
        "    ('tfidf_basic', 'logistic_regression'),\n",
        "    ('tfidf_ngram', 'naive_bayes'),\n",
        "    ('count_ngram', 'naive_bayes')\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for vec_name, model_name in promising_combos:\n",
        "    try:\n",
        "        score, vectorizer, model = evaluate_model(vec_name, model_name, X_train, X_val, y_train, y_val, vectorizers, models)\n",
        "        results.append((vec_name, model_name, score))\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_combo = (vec_name, model_name)\n",
        "            best_vectorizer = vectorizer\n",
        "            best_model = model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error with {vec_name} + {model_name}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\n=== RESULTS ===\")\n",
        "for vec_name, model_name, score in sorted(results, key=lambda x: x[2], reverse=True):\n",
        "    print(f\"{vec_name} + {model_name}: {score:.2f}\")\n",
        "\n",
        "print(f\"\\nBest combination: {best_combo[0]} + {best_combo[1]} with score: {best_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5iXbV2Ptsq4",
        "outputId": "91a4ef1c-c498-4341-e1ca-ad8e8e4e8ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating tfidf_ngram + logistic_regression...\n",
            "Macro F1 Score: 0.8678\n",
            "Evaluation Score: 86.78\n",
            "\n",
            "Evaluating tfidf_advanced + logistic_regression...\n",
            "Macro F1 Score: 0.8665\n",
            "Evaluation Score: 86.65\n",
            "\n",
            "Evaluating tfidf_basic + logistic_regression...\n",
            "Macro F1 Score: 0.8655\n",
            "Evaluation Score: 86.55\n",
            "\n",
            "Evaluating tfidf_ngram + naive_bayes...\n",
            "Macro F1 Score: 0.8503\n",
            "Evaluation Score: 85.03\n",
            "\n",
            "Evaluating count_ngram + naive_bayes...\n",
            "Macro F1 Score: 0.8751\n",
            "Evaluation Score: 87.51\n",
            "\n",
            "=== RESULTS ===\n",
            "count_ngram + naive_bayes: 87.51\n",
            "tfidf_ngram + logistic_regression: 86.78\n",
            "tfidf_advanced + logistic_regression: 86.65\n",
            "tfidf_basic + logistic_regression: 86.55\n",
            "tfidf_ngram + naive_bayes: 85.03\n",
            "\n",
            "Best combination: count_ngram + naive_bayes with score: 87.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get detailed results for the best model\n",
        "print(\"Detailed evaluation for best model: count_ngram + naive_bayes\")\n",
        "\n",
        "# Use the best combination\n",
        "vectorizer = CountVectorizer(max_features=15000, ngram_range=(1, 2), stop_words='english', max_df=0.95, min_df=2)\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Fit on training data\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_val_vec = vectorizer.transform(X_val)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Get predictions\n",
        "y_pred = model.predict(X_val_vec)\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Per-class F1 scores\n",
        "from sklearn.metrics import f1_score\n",
        "per_class_f1 = f1_score(y_val, y_pred, average=None)\n",
        "classes = sorted(y_val.unique())\n",
        "print(\"\\nPer-class F1 scores:\")\n",
        "for class_name, f1 in zip(classes, per_class_f1):\n",
        "    print(f\"{class_name}: {f1:.4f}\")\n",
        "\n",
        "print(f\"\\nMacro F1: {f1_score(y_val, y_pred, average='macro'):.4f}\")\n",
        "print(f\"Weighted F1: {f1_score(y_val, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Final Score: {100 * f1_score(y_val, y_pred, average='macro'):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yaj0zl8txqd",
        "outputId": "4ad89838-b0c4-4109-9386-4d3a7da32c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed evaluation for best model: count_ngram + naive_bayes\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Computer Sciences       0.86      0.94      0.90       208\n",
            "           Gaming       0.86      0.89      0.88       328\n",
            "        Geography       0.89      0.83      0.86       283\n",
            "          History       0.89      0.89      0.89       148\n",
            " Natural Sciences       0.86      0.91      0.89       278\n",
            "      Pop Culture       0.88      0.77      0.82       313\n",
            "           Sports       0.89      0.91      0.90       442\n",
            "\n",
            "         accuracy                           0.88      2000\n",
            "        macro avg       0.88      0.88      0.88      2000\n",
            "     weighted avg       0.88      0.88      0.87      2000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[196   4   1   0   4   2   1]\n",
            " [  6 292   7   2   5   7   9]\n",
            " [  4   5 234   3  20  10   7]\n",
            " [  1   4   8 132   0   1   2]\n",
            " [  7   4   3   2 254   3   5]\n",
            " [ 12  21   4   4   5 240  27]\n",
            " [  3   8   7   5   6  11 402]]\n",
            "\n",
            "Per-class F1 scores:\n",
            "Computer Sciences: 0.8970\n",
            "Gaming: 0.8769\n",
            "Geography: 0.8556\n",
            "History: 0.8919\n",
            "Natural Sciences: 0.8881\n",
            "Pop Culture: 0.8177\n",
            "Sports: 0.8983\n",
            "\n",
            "Macro F1: 0.8751\n",
            "Weighted F1: 0.8741\n",
            "Final Score: 87.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's also try an ensemble approach or hyperparameter tuning for better results\n",
        "# First, let's try some hyperparameter tuning for the CountVectorizer + NB combination\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"Performing hyperparameter tuning for CountVectorizer + MultinomialNB...\")\n",
        "\n",
        "# Define parameter grids\n",
        "vectorizer_params = [\n",
        "    {'max_features': [10000, 15000, 20000], 'min_df': [2, 3, 5], 'max_df': [0.9, 0.95, 0.98]},\n",
        "]\n",
        "\n",
        "nb_params = [\n",
        "    {'alpha': [0.1, 0.5, 1.0, 2.0]}\n",
        "]\n",
        "\n",
        "best_tuned_score = 0\n",
        "best_tuned_vectorizer = None\n",
        "best_tuned_model = None\n",
        "\n",
        "# Try different vectorizer parameters\n",
        "for vec_params in vectorizer_params:\n",
        "    for max_feat in vec_params['max_features']:\n",
        "        for min_df in vec_params['min_df']:\n",
        "            for max_df in vec_params['max_df']:\n",
        "                print(f\"Testing max_features={max_feat}, min_df={min_df}, max_df={max_df}\")\n",
        "\n",
        "                vectorizer = CountVectorizer(max_features=max_feat, ngram_range=(1, 2),\n",
        "                                           stop_words='english', max_df=max_df, min_df=min_df)\n",
        "\n",
        "                X_train_vec = vectorizer.fit_transform(X_train)\n",
        "                X_val_vec = vectorizer.transform(X_val)\n",
        "\n",
        "                # Try different alpha values for MultinomialNB\n",
        "                for alpha in [0.1, 0.5, 1.0, 2.0]:\n",
        "                    model = MultinomialNB(alpha=alpha)\n",
        "                    model.fit(X_train_vec, y_train)\n",
        "\n",
        "                    y_pred = model.predict(X_val_vec)\n",
        "                    score = 100 * f1_score(y_val, y_pred, average='macro')\n",
        "\n",
        "                    if score > best_tuned_score:\n",
        "                        best_tuned_score = score\n",
        "                        best_tuned_vectorizer = vectorizer\n",
        "                        best_tuned_model = model\n",
        "                        print(f\"  New best score: {score:.2f} (alpha={alpha})\")\n",
        "\n",
        "print(f\"\\nBest tuned score: {best_tuned_score:.2f}\")\n",
        "\n",
        "# If tuning didn't improve much, let's stick with the original best model\n",
        "if best_tuned_score <= best_score + 0.5:  # If improvement is minimal\n",
        "    print(\"Tuning didn't provide significant improvement. Using original best model.\")\n",
        "    final_vectorizer = CountVectorizer(max_features=15000, ngram_range=(1, 2), stop_words='english', max_df=0.95, min_df=2)\n",
        "    final_model = MultinomialNB()\n",
        "else:\n",
        "    print(\"Using tuned model.\")\n",
        "    final_vectorizer = best_tuned_vectorizer\n",
        "    final_model = best_tuned_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmZi0NkUt9YT",
        "outputId": "e98dad86-d261-4658-aa6b-3f5a437a7cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing hyperparameter tuning for CountVectorizer + MultinomialNB...\n",
            "Testing max_features=10000, min_df=2, max_df=0.9\n",
            "  New best score: 87.38 (alpha=0.1)\n",
            "  New best score: 87.42 (alpha=0.5)\n",
            "Testing max_features=10000, min_df=2, max_df=0.95\n",
            "Testing max_features=10000, min_df=2, max_df=0.98\n",
            "Testing max_features=10000, min_df=3, max_df=0.9\n",
            "Testing max_features=10000, min_df=3, max_df=0.95\n",
            "Testing max_features=10000, min_df=3, max_df=0.98\n",
            "Testing max_features=10000, min_df=5, max_df=0.9\n",
            "Testing max_features=10000, min_df=5, max_df=0.95\n",
            "Testing max_features=10000, min_df=5, max_df=0.98\n",
            "Testing max_features=15000, min_df=2, max_df=0.9\n",
            "  New best score: 88.27 (alpha=0.1)\n",
            "Testing max_features=15000, min_df=2, max_df=0.95\n",
            "Testing max_features=15000, min_df=2, max_df=0.98\n",
            "Testing max_features=15000, min_df=3, max_df=0.9\n",
            "Testing max_features=15000, min_df=3, max_df=0.95\n",
            "Testing max_features=15000, min_df=3, max_df=0.98\n",
            "Testing max_features=15000, min_df=5, max_df=0.9\n",
            "Testing max_features=15000, min_df=5, max_df=0.95\n",
            "Testing max_features=15000, min_df=5, max_df=0.98\n",
            "Testing max_features=20000, min_df=2, max_df=0.9\n",
            "  New best score: 88.32 (alpha=0.5)\n",
            "Testing max_features=20000, min_df=2, max_df=0.95\n",
            "Testing max_features=20000, min_df=2, max_df=0.98\n",
            "Testing max_features=20000, min_df=3, max_df=0.9\n",
            "Testing max_features=20000, min_df=3, max_df=0.95\n",
            "Testing max_features=20000, min_df=3, max_df=0.98\n",
            "Testing max_features=20000, min_df=5, max_df=0.9\n",
            "Testing max_features=20000, min_df=5, max_df=0.95\n",
            "Testing max_features=20000, min_df=5, max_df=0.98\n",
            "\n",
            "Best tuned score: 88.32\n",
            "Using tuned model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's train the final model on the entire training dataset and make predictions on the test set\n",
        "\n",
        "print(\"Training final model on entire training dataset...\")\n",
        "\n",
        "# Use the best parameters found: max_features=20000, min_df=2, max_df=0.9, alpha=0.5\n",
        "final_vectorizer = CountVectorizer(max_features=20000, ngram_range=(1, 2),\n",
        "                                 stop_words='english', max_df=0.9, min_df=2)\n",
        "final_model = MultinomialNB(alpha=0.5)\n",
        "\n",
        "# Train on the entire training set\n",
        "X_full_train = train_df['processed_text']\n",
        "y_full_train = train_df['Subject']\n",
        "\n",
        "X_full_train_vec = final_vectorizer.fit_transform(X_full_train)\n",
        "final_model.fit(X_full_train_vec, y_full_train)\n",
        "\n",
        "print(\"Final model trained successfully!\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "print(\"Making predictions on test set...\")\n",
        "X_test_processed = test_df['processed_text']\n",
        "X_test_vec = final_vectorizer.transform(X_test_processed)\n",
        "test_predictions = final_model.predict(X_test_vec)\n",
        "\n",
        "print(\"Predictions completed!\")\n",
        "\n",
        "# Create submission dataframe\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_df['ID'],\n",
        "    'Subject': test_predictions\n",
        "})\n",
        "\n",
        "print(f\"Submission shape: {submission.shape}\")\n",
        "print(f\"Unique predictions: {submission['Subject'].unique()}\")\n",
        "print(f\"Prediction distribution:\")\n",
        "print(submission['Subject'].value_counts())\n",
        "\n",
        "# Display first few predictions\n",
        "print(f\"\\nFirst 10 predictions:\")\n",
        "print(submission.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OyzAKcJuCTC",
        "outputId": "f18eec70-467d-4b80-9b0b-a7b023a3846f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training final model on entire training dataset...\n",
            "Final model trained successfully!\n",
            "Making predictions on test set...\n",
            "Predictions completed!\n",
            "Submission shape: (4020, 2)\n",
            "Unique predictions: ['Gaming' 'Pop Culture' 'Computer Sciences' 'Geography' 'Natural Sciences'\n",
            " 'History' 'Sports']\n",
            "Prediction distribution:\n",
            "Subject\n",
            "Sports               909\n",
            "Gaming               645\n",
            "Pop Culture          593\n",
            "Natural Sciences     552\n",
            "Geography            541\n",
            "Computer Sciences    516\n",
            "History              264\n",
            "Name: count, dtype: int64\n",
            "\n",
            "First 10 predictions:\n",
            "          ID            Subject\n",
            "0  test_0001             Gaming\n",
            "1  test_0002        Pop Culture\n",
            "2  test_0003  Computer Sciences\n",
            "3  test_0004          Geography\n",
            "4  test_0005        Pop Culture\n",
            "5  test_0006             Gaming\n",
            "6  test_0007   Natural Sciences\n",
            "7  test_0008            History\n",
            "8  test_0009        Pop Culture\n",
            "9  test_0010             Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's validate our model once more using cross-validation on the full training set\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "print(\"Performing 5-fold cross-validation on full training set...\")\n",
        "\n",
        "# Use the final model configuration\n",
        "final_vectorizer_cv = CountVectorizer(max_features=20000, ngram_range=(1, 2),\n",
        "                                    stop_words='english', max_df=0.9, min_df=2)\n",
        "final_model_cv = MultinomialNB(alpha=0.5)\n",
        "\n",
        "# Transform the text\n",
        "X_full_vec = final_vectorizer_cv.fit_transform(X_full_train)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(final_model_cv, X_full_vec, y_full_train,\n",
        "                           cv=5, scoring='f1_macro')\n",
        "\n",
        "print(f\"Cross-validation F1 macro scores: {cv_scores}\")\n",
        "print(f\"Mean CV F1 macro: {cv_scores.mean():.4f}\")\n",
        "print(f\"Std CV F1 macro: {cv_scores.std():.4f}\")\n",
        "print(f\"Mean CV Score (100 * F1): {100 * cv_scores.mean():.2f}\")\n",
        "\n",
        "# Save the predictions to CSV\n",
        "submission.to_csv('prediction.csv', index=False)\n",
        "print(f\"\\nPredictions saved to 'prediction.csv'\")\n",
        "\n",
        "# Verify the submission format\n",
        "print(f\"\\nVerifying submission format:\")\n",
        "print(f\"Shape: {submission.shape}\")\n",
        "print(f\"Columns: {submission.columns.tolist()}\")\n",
        "print(f\"Index matches test file IDs: {submission['ID'].equals(test_df['ID'])}\")\n",
        "print(f\"All subjects are valid: {set(submission['Subject'].unique()).issubset(set(train_df['Subject'].unique()))}\")\n",
        "\n",
        "print(\"\\n=== FINAL MODEL SUMMARY ===\")\n",
        "print(f\"Vectorizer: CountVectorizer with max_features=20000, ngram_range=(1,2), max_df=0.9, min_df=2\")\n",
        "print(f\"Model: MultinomialNB with alpha=0.5\")\n",
        "print(f\"Expected performance (CV): {100 * cv_scores.mean():.2f} ± {100 * cv_scores.std():.2f}\")\n",
        "print(f\"Submission file: prediction.csv ({submission.shape[0]} predictions)\")\n",
        "\n",
        "submission.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "_eQHvBUmucZe",
        "outputId": "56b85107-f62c-475e-8cec-e5e1312d403b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 5-fold cross-validation on full training set...\n",
            "Cross-validation F1 macro scores: [0.88215912 0.8876484  0.90033131 0.86713556 0.8694774 ]\n",
            "Mean CV F1 macro: 0.8814\n",
            "Std CV F1 macro: 0.0122\n",
            "Mean CV Score (100 * F1): 88.14\n",
            "\n",
            "Predictions saved to 'submission.csv'\n",
            "\n",
            "Verifying submission format:\n",
            "Shape: (4020, 2)\n",
            "Columns: ['ID', 'Subject']\n",
            "Index matches test file IDs: True\n",
            "All subjects are valid: True\n",
            "\n",
            "=== FINAL MODEL SUMMARY ===\n",
            "Vectorizer: CountVectorizer with max_features=20000, ngram_range=(1,2), max_df=0.9, min_df=2\n",
            "Model: MultinomialNB with alpha=0.5\n",
            "Expected performance (CV): 88.14 ± 1.22\n",
            "Submission file: submission.csv (4020 predictions)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ID            Subject\n",
              "0  test_0001             Gaming\n",
              "1  test_0002        Pop Culture\n",
              "2  test_0003  Computer Sciences\n",
              "3  test_0004          Geography\n",
              "4  test_0005        Pop Culture\n",
              "5  test_0006             Gaming\n",
              "6  test_0007   Natural Sciences\n",
              "7  test_0008            History\n",
              "8  test_0009        Pop Culture\n",
              "9  test_0010             Sports"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbb2321a-d735-45c1-b397-79ee396dd88c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0001</td>\n",
              "      <td>Gaming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_0002</td>\n",
              "      <td>Pop Culture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_0003</td>\n",
              "      <td>Computer Sciences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_0004</td>\n",
              "      <td>Geography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_0005</td>\n",
              "      <td>Pop Culture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>test_0006</td>\n",
              "      <td>Gaming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>test_0007</td>\n",
              "      <td>Natural Sciences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>test_0008</td>\n",
              "      <td>History</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>test_0009</td>\n",
              "      <td>Pop Culture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>test_0010</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbb2321a-d735-45c1-b397-79ee396dd88c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbb2321a-d735-45c1-b397-79ee396dd88c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbb2321a-d735-45c1-b397-79ee396dd88c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-814d2e76-f166-4093-b541-57740b071229\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-814d2e76-f166-4093-b541-57740b071229')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-814d2e76-f166-4093-b541-57740b071229 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission",
              "summary": "{\n  \"name\": \"submission\",\n  \"rows\": 4020,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4020,\n        \"samples\": [\n          \"test_2982\",\n          \"test_1205\",\n          \"test_2721\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subject\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Gaming\",\n          \"Pop Culture\",\n          \"History\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the cross-validation call and complete the submission\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "print(\"Performing 5-fold cross-validation on full training set...\")\n",
        "\n",
        "# Use the final model configuration\n",
        "final_vectorizer_cv = CountVectorizer(max_features=20000, ngram_range=(1, 2),\n",
        "                                    stop_words='english', max_df=0.9, min_df=2)\n",
        "final_model_cv = MultinomialNB(alpha=0.5)\n",
        "\n",
        "# Transform the text\n",
        "X_full_vec = final_vectorizer_cv.fit_transform(X_full_train)\n",
        "\n",
        "# Perform cross-validation with StratifiedKFold for reproducibility\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(final_model_cv, X_full_vec, y_full_train,\n",
        "                           cv=skf, scoring='f1_macro')\n",
        "\n",
        "print(f\"Cross-validation F1 macro scores: {cv_scores}\")\n",
        "print(f\"Mean CV F1 macro: {cv_scores.mean():.4f}\")\n",
        "print(f\"Std CV F1 macro: {cv_scores.std():.4f}\")\n",
        "print(f\"Mean CV Score (100 * F1): {100 * cv_scores.mean():.2f}\")\n",
        "\n",
        "# Save the predictions to CSV\n",
        "submission.to_csv('prediction.csv', index=False)\n",
        "print(f\"\\nPredictions saved to 'prediction.csv'\")\n",
        "\n",
        "# Verify the submission format\n",
        "print(f\"\\nVerifying submission format:\")\n",
        "print(f\"Shape: {submission.shape}\")\n",
        "print(f\"Columns: {submission.columns.tolist()}\")\n",
        "print(f\"Index matches test file IDs: {submission['ID'].equals(test_df['ID'])}\")\n",
        "print(f\"All subjects are valid: {set(submission['Subject'].unique()).issubset(set(train_df['Subject'].unique()))}\")\n",
        "\n",
        "print(\"\\n=== FINAL MODEL SUMMARY ===\")\n",
        "print(f\"Vectorizer: CountVectorizer with max_features=20000, ngram_range=(1,2), max_df=0.9, min_df=2\")\n",
        "print(f\"Model: MultinomialNB with alpha=0.5\")\n",
        "print(f\"Expected performance (CV): {100 * cv_scores.mean():.2f} ± {100 * cv_scores.std():.2f}\")\n",
        "print(f\"Submission file: prediction.csv ({submission.shape[0]} predictions)\")\n",
        "\n",
        "# Check if we have all required files\n",
        "import os\n",
        "files_in_dir = os.listdir('.')\n",
        "print(f\"\\nFiles created: {[f for f in files_in_dir if f.endswith('.csv')]}\")\n",
        "print(\"prediction.csv ready for upload!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi6CGOIfuw6y",
        "outputId": "c343eb42-633b-40ac-d5a3-4f29fb9beb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 5-fold cross-validation on full training set...\n",
            "Cross-validation F1 macro scores: [0.87638371 0.88323856 0.8837605  0.87485903 0.88994307]\n",
            "Mean CV F1 macro: 0.8816\n",
            "Std CV F1 macro: 0.0055\n",
            "Mean CV Score (100 * F1): 88.16\n",
            "\n",
            "Predictions saved to 'submission.csv'\n",
            "\n",
            "Verifying submission format:\n",
            "Shape: (4020, 2)\n",
            "Columns: ['ID', 'Subject']\n",
            "Index matches test file IDs: True\n",
            "All subjects are valid: True\n",
            "\n",
            "=== FINAL MODEL SUMMARY ===\n",
            "Vectorizer: CountVectorizer with max_features=20000, ngram_range=(1,2), max_df=0.9, min_df=2\n",
            "Model: MultinomialNB with alpha=0.5\n",
            "Expected performance (CV): 88.16 ± 0.55\n",
            "Submission file: submission.csv (4020 predictions)\n",
            "\n",
            "Files created: ['train.csv', 'submission.csv', 'sample_submission.csv', 'test.csv']\n",
            "submission.csv ready for upload!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "beXRUVXavfQz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}